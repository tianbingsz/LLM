{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b24cb4dd-196b-45a3-a78e-8b08ec11c338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DPO with Mistral series model as the base model.\n",
    "# Use DPO to improve open LLMs using Hugging Face TRL, Transformers\n",
    "# https://github.com/philschmid/deep-learning-pytorch-huggingface/blob/main/training/dpo-align-llms-in-2024-with-trl.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49016add-2fd7-4fb1-87e2-930892817080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENV Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "023271f3-4a48-44b4-8031-d3db5b6a79a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python -m pip install --upgrade pip\n",
    "# pip install torch==2.1.1+cu118 torchvision torchaudio -f https://download.pytorch.org/whl/cu118/torch_stable.html \n",
    "# pip install  --upgrade \\\n",
    "#  \"transformers[sentencepiece]==4.37.2\" \\\n",
    "#  \"datasets==2.16.1\" \\\n",
    "#  \"accelerate==0.26.1\" \\\n",
    "#  \"evaluate==0.4.1\" \\\n",
    "#  \"bitsandbytes==0.42.0\" \\\n",
    "#  \"trl==0.7.11\" \\\n",
    "#  \"peft==0.8.2\" \\\n",
    "#  \"pillow\"\n",
    "\n",
    "# install flash-attn\n",
    "#pip install ninja packaging\n",
    "#MAX_JOBS=4 pip install flash-attn --no-build-isolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17a73d31-c8d6-4597-9935-87af1ba088d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d56bfc3c-6cb0-4e45-9a66-4ae559eec47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pytorch version:  2.2.2+cu118\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n pytorch version: \", torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e374cd0-3d16-400b-9293-ab6d13a269bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " gpu available:  True\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n gpu available: \", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ee10e4c-efd2-4d54-9b0e-157c2b6c0512",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.cuda.get_device_capability()[0] >= 8, 'Hardware not supported for Flash Attention'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de46c817-b999-46a4-be7a-d47f27f2ab9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device capacity:  8\n"
     ]
    }
   ],
   "source": [
    "print(\"device capacity: \", torch.cuda.get_device_capability()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63eff585-5c2c-4599-893f-3c645ebe9dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HuggingFace Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d164f2c9-e62d-4a4e-8365-eb7d2d5fc5d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid (permission: write).\n",
      "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
      "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
      "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
      "\n",
      "git config --global credential.helper store\n",
      "\n",
      "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
      "Token has not been saved to git credential helper.\n",
      "Your token has been saved to /home/tianbing_xu/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(\n",
    "  token=\"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\", # ADD YOUR TOKEN HERE\n",
    "  add_to_git_credential=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7fea066-d89b-4be2-b053-3923794cab43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd82666f-54eb-42a3-9eac-2c190e9764f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65cdf46490de4899abdd56fb821fdf80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.69k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "741637503f244bfc81200c7a55b51c7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a53b09911d404d16abafbcfec22e3fab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/51.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7507dd4feca642719988f3ffd5dd24b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/100 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c6a8f29a80545d6b8669ce74131a6b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/4.46k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "129c37522c4c4803a544d0a759428240",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/143M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5b88808bd1843548566234834ccebc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/60917 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c27bd41d097a45ff92a318bb8349ce91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13750 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a2b312609eb4fcea26821f0e1a51a94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/11 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "631fe6eafee14a4599d7319950cf14bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "9491410"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load Tokenizer from the hub\n",
    "model_id = \"cognitivecomputations/dolphin-2.1-mistral-7b\" # replace with your model id\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "# Load dataset from the hub\n",
    "dataset = load_dataset(\"argilla/ultrafeedback-binarized-preferences-cleaned\", split=\"train\")\n",
    "dataset = dataset.shuffle().select(range(13750))\n",
    "\n",
    "\n",
    "def rec_extract_assistant_messages(messages, index=-1):\n",
    "  \"\"\"Recursively extract the last assistant messages from the end of the conversation.\"\"\"\n",
    "  if messages[index][\"role\"] == \"assistant\":\n",
    "    return [messages[index]]\n",
    "  else:\n",
    "    return rec_extract_assistant_messages(messages, index-1)\n",
    "    \n",
    "# System message used if there is no system message at the beginning of the conversation\n",
    "# Can be repelaced and modified as needed\n",
    "DEFAULT_SYSTEM_MESSAGE = \"You are Dolphin, a helpful AI assistant.\"\n",
    "\n",
    "def create_triplets(example, tokenizer, default_system_message=DEFAULT_SYSTEM_MESSAGE):\n",
    "  \"\"\"Create the triplets (prompt, chosen, rejected)\"\"\"\n",
    "  # Extract the N-1 turns to form the prompt\n",
    "  # Prepend a system message if the first message is not a system message\n",
    "  prompt_messages = example[\"chosen\"][:-1]\n",
    "  if example[\"chosen\"][0][\"role\"] != \"system\":\n",
    "      prompt_messages.insert(0, {\"role\": \"system\", \"content\": default_system_message})\n",
    "  # Now we extract the final assistant turn to define chosen/rejected responses \n",
    "  chosen_messages = rec_extract_assistant_messages(example[\"chosen\"])\n",
    "  rejected_messages = rec_extract_assistant_messages(example[\"rejected\"])\n",
    "  \n",
    "  # apply template to the messages and return the triplets\n",
    "  return {\n",
    "    \"prompt\": tokenizer.apply_chat_template(prompt_messages, tokenize=False),\n",
    "    \"chosen\": tokenizer.apply_chat_template(chosen_messages, tokenize=False),\n",
    "    \"rejected\": tokenizer.apply_chat_template(rejected_messages, tokenize=False)\n",
    "  }\n",
    "\n",
    "dataset = dataset.map(create_triplets, remove_columns=dataset.features, fn_kwargs={\"tokenizer\": tokenizer})  \n",
    "# split dataset into 11,000 training samples and 2,750 test samples\n",
    "dataset = dataset.train_test_split(test_size=2750/13750)\n",
    "\n",
    "# save datasets to disk\n",
    "dataset[\"train\"].to_json(\"train_dataset.json\", orient=\"records\")\n",
    "dataset[\"test\"].to_json(\"test_dataset.json\", orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f358bfbf-2f49-4c7c-a37f-ca3f4838ca78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are Dolphin, a helpful AI assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "Give me a brief scenario of a persona that would search this information and find this content helpful: Master Builders Cost plus residential contracts in NSW - Head contract for work undertaken on a cost plus fixed fee or percentage margin basis.<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dataset[\"train\"][0][\"prompt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfe324f2-0b9c-49f5-9f8a-dbfdd5c9bb92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>assistant\n",
      "Meet Sarah, a 35-year-old architect residing in Sydney, New South Wales. Recently, she has started her own small architecture firm, aiming to deliver innovative residential projects to her clients.\n",
      "\n",
      "Sarah's firm has been growing steadily, and she has just won the commission for a custom-designed residential project for the Taylor family. Emphasizing high-quality craftsmanship, the project has unique requirements that cannot be covered by standard pricing. Due to fluctuating material prices and the nature of custom work, it makes more sense for Sarah and her team to suggest a cost-plus contract for Taylor's dream home construction.\n",
      "\n",
      "Sarah is determined to find the best resources to manage her project, protect her clients' and firm's interests, and ensure smooth completion. To avoid disputes, she knows it's essential to have a solid contract in place, so she ventures to find information regarding Master Builders Cost-Plus Residential Contracts in NSW.\n",
      "\n",
      "From her targeted search, Sarah finds the perfect resource that provides her valuable insights about structuring cost-plus residential contracts in NSW on a fixed fee or percentage margin basis. As she reads through the content, she learns how to tailor the head contract in a way that accommodates unique project requirements and clarifies the terms of the cost-plus arrangement for both parties.\n",
      "\n",
      "Sarah realizes the potential value of using this cost-plus contract template for her future projects as well, saving time and effort while ensuring a reliable contractual basis to protect her firm and her clients.<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dataset[\"train\"][0][\"chosen\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a68fc9ef-191e-4477-bccc-906869811ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>assistant\n",
      "Do you need assistance with any queries you may have?<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dataset[\"train\"][0][\"rejected\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d8bddb2-1a0b-46fb-9c39-46ba9fa7c6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b0e22c3-1494-4d30-bbcd-4f1acdc5a56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fd2cc1b-362a-4877-b2a8-a0daf3ccd934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4c35d5c9b364e01bd49a2be03cce64b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fab6002dbb1f4d77b370724af2beab8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load jsonl data from disk\n",
    "train_dataset = load_dataset(\"json\", data_files=\"train_dataset.json\", split=\"train\")\n",
    "eval_dataset = load_dataset(\"json\", data_files=\"test_dataset.json\", split=\"train\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47fc881f-67c6-4dcd-abbf-adb4c8af9fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_train_dataset = train_dataset.select(range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d69a6a2-b86d-4bc5-bae9-abe1cf971e80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'chosen', 'rejected'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c7204ca-d07b-4a37-9134-39d26e812e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_eval_dataset = eval_dataset.select(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0e931af-5d33-48d4-a3f1-7cd6a62641c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'chosen', 'rejected'],\n",
       "    num_rows: 100\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d69698b2-3971-47c0-9a20-2966b9d0f5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load model mistral dolphin (int-4 using bitsandbytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac6dd0cc-9443-4bb5-930e-054120258ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae69d0735b564870bbf8334f1fa268df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/622 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0ad74ca56564df59ddff7c600f0edf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f471ac91d96475a8cae83a68dabc293",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d3a86124a60405e9e84b93658783053",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e3fe499758c468f8a4158bd5de2b321",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "986d0310d33c45cca3adb67e4084b417",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "155831bf5d9b4d23a46a565ebcacd25e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "# Hugging Face model id\n",
    "model_id = \"cognitivecomputations/dolphin-2.1-mistral-7b\" # replace with your model id\n",
    "\n",
    "# BitsAndBytesConfig int-4 config\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True, bnb_4bit_use_double_quant=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "# Load model and tokenizer\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    use_cache=False, \n",
    "    attn_implementation=\"flash_attention_2\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    quantization_config=bnb_config\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = 'left' # to prevent errors with FA\n",
    "tokenizer.truncation_side = 'left' # to prevent cutting off last generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db0072f1-dd40-4a99-8cd1-abcc51369b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The max_prompt_length is the maximum length of the prompt and the max_length is the maximum length of the prompt + chosen or rejected response\n",
    "max_length = 1024\n",
    "max_prompt_length = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fe12d0f4-1bac-48b3-a1d1-2ff27c7b6fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## perf using qlora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "530f2211-6de1-4dd5-a862-fe8bbfe361b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig\n",
    "\n",
    "# LoRA config based on QLoRA paper & Sebastian Raschka experiment\n",
    "peft_config = LoraConfig(\n",
    "        lora_alpha=64,\n",
    "        lora_dropout=0.05,\n",
    "        r=64,\n",
    "        bias=\"none\",\n",
    "        target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "        task_type=\"CAUSAL_LM\", \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "43ce172c-73b5-40fa-bd21-dc2c90f392d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## training args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "955df86d-624e-4403-a9e1-93eacebea649",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"doplhin-dpo_2\",             # directory to save and repository id\n",
    "    num_train_epochs=1,                     # number of training epochs\n",
    "    per_device_train_batch_size=2,         # batch size per device during training\n",
    "    per_device_eval_batch_size=1,           # batch size for evaluation\n",
    "    gradient_accumulation_steps=1,          # number of steps before performing a backward/update pass\n",
    "    gradient_checkpointing=True,            # use gradient checkpointing to save memory\n",
    "    optim=\"adamw_torch_fused\",              # use fused adamw optimizer\n",
    "    learning_rate=5e-5,                     # 10x higher LR than QLoRA paper\n",
    "    max_grad_norm=0.3,                      # max gradient norm based on QLoRA paper\n",
    "    warmup_ratio=0.1,                       # warmup ratio based on QLoRA paper\n",
    "    lr_scheduler_type=\"cosine\",             # use cosine learning rate scheduler\n",
    "    logging_steps=25,                       # log every 25 steps\n",
    "    save_steps=500,                         # when to save checkpoint\n",
    "    save_total_limit=2,                     # limit the total amount of checkpoints\n",
    "    evaluation_strategy=\"steps\",            # evaluate every 1000 steps\n",
    "    eval_steps=700,                         # when to evaluate\n",
    "    bf16=True,                              # use bfloat16 precision\n",
    "    tf32=True,                              # use tf32 precision\n",
    "    push_to_hub=False,                      # push model to hub\n",
    "    report_to=\"tensorboard\",                # report metrics to tensorboard\n",
    ")\n",
    "\n",
    "dpo_args = {\n",
    "    \"beta\": 0.1,                            # The beta factor in DPO loss. Higher beta means less divergence\n",
    "    \"loss_type\": \"sigmoid\"                  # The loss type for DPO.\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "33101560-e43f-4ad3-8740-bde2448ef556",
   "metadata": {},
   "outputs": [],
   "source": [
    "## dpo trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e03812c-7366-4bd5-92e4-b41531584119",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-12 17:59:17.735891: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-12 17:59:17.774442: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-12 17:59:18.524031: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/default_user/.conda/envs/user/lib/python3.10/site-packages/trl/trainer/dpo_trainer.py:328: UserWarning: When using DPODataCollatorWithPadding, you should set `remove_unused_columns=False` in your TrainingArguments we have set it for you, but you should do it yourself in the future.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "856d7aff82394eb888496c49ba715ca0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6345cd39650a460b8e42b059ff11741c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from trl import DPOTrainer\n",
    "\n",
    "trainer = DPOTrainer(\n",
    "    model,\n",
    "    ref_model=None, # set to none since we use peft\n",
    "    peft_config=peft_config,\n",
    "    args=args,\n",
    "    train_dataset=sub_train_dataset,\n",
    "    eval_dataset=sub_eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=max_length,\n",
    "    max_prompt_length=max_prompt_length,\n",
    "    beta=dpo_args[\"beta\"],\n",
    "    loss_type=dpo_args[\"loss_type\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff55f60a-3e53-4555-8806-59b496b537a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "94ed6c25-1c75-4e00-9060-a6394af6b861",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/default_user/.conda/envs/user/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "The input hidden states seems to be silently casted in float32, this might be related to the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in torch.bfloat16.\n",
      "/home/default_user/.conda/envs/user/lib/python3.10/site-packages/torch/utils/checkpoint.py:90: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 44:32, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=500, training_loss=0.9739822273254395, metrics={'train_runtime': 2681.5067, 'train_samples_per_second': 0.373, 'train_steps_per_second': 0.186, 'total_flos': 0.0, 'train_loss': 0.9739822273254395, 'epoch': 1.0})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start training, the model will be automatically saved to the hub and the output directory\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "09659c1b-c941-4ca3-9230-d36f5692133e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model at the end of training\n",
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "43287f92-ef97-424c-bfde-fd2c2905221e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## free the memory again\n",
    "del model\n",
    "del trainer\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63220a1f-214b-440e-b13e-63b299b832c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load DPO fine-tuned model and inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b50ecc9-fd12-45a6-9a22-dafb19e906b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-12 18:46:58.187708: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-12 18:46:58.232733: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-12 18:46:59.031469: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16716b0201314181b61f4ff4343872f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "The model 'PeftModelForCausalLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FuyuForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'LlamaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MvpForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'Qwen2ForCausalLM', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from peft import AutoPeftModelForCausalLM\n",
    "from transformers import AutoTokenizer, pipeline \n",
    "\n",
    "# Path to saved peft adapter model\n",
    "# peft_model_id = args.output_dir # or\n",
    "peft_model_id = \"./doplhin-dpo_2\" \n",
    "\n",
    "# Load Model with PEFT adapter\n",
    "model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "  peft_model_id,\n",
    "  device_map=\"cuda\",\n",
    "  torch_dtype=torch.float16\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(peft_model_id)\n",
    "# load into pipeline\n",
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89963bf7-9764-4414-986f-4d3268caaf42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] Do you have mayonnaise recipes? [/INST]\n",
      "\n",
      "YES! Here are three delicious and easy-to-make homemade mayonnaise recipes:\n",
      "\n",
      "1. Basic Mayonnaise:\n",
      "\n",
      "Ingredients:\n",
      "- 1 large egg yolk (at room temperature)\n",
      "- 1 tablespoon fresh lemon juice\n",
      "- 1 teaspoon dijon mustard\n",
      "- 1/4 teaspoon salt\n",
      "- 1/4 teaspoon ground black pepper\n",
      "- 1 cup vegetable oil (such as safflower, sunflower, or soybean oil)\n",
      "\n",
      "Instructions:\n",
      "\n",
      "1. In a bowl, whisk together the egg yolk, lemon juice, mustard, salt, and black pepper until well combined.\n",
      "2. Slowly add the vegetable oil, drop by drop, or in a very thin stream, while continuously whisking. As the mayo begins to thicken,\n"
     ]
    }
   ],
   "source": [
    "text = \"[INST] Do you have mayonnaise recipes? [/INST]\"\n",
    "\n",
    "# Tokenize the input text\n",
    "encodeds = tokenizer(text, return_tensors=\"pt\", add_special_tokens=False)\n",
    "\n",
    "# Generate text using the model\n",
    "generated_ids = model.generate(\n",
    "    input_ids=encodeds.input_ids.to(\"cuda\"),\n",
    "    attention_mask=encodeds.attention_mask.to(\"cuda\"),  # Pass attention mask\n",
    "    max_length=200,\n",
    "    do_sample=True,\n",
    "    pad_token_id=tokenizer.eos_token_id  # Set pad_token_id to eos_token_id\n",
    ")\n",
    "\n",
    "# Decode the generated tokens\n",
    "decoded = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "\n",
    "# Print the decoded text\n",
    "print(decoded[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74be2d52-6c87-4e42-8346-5e519340f933",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "  \"A rectangular garden has a length of 25 feet and a width of 15 feet. If you want to build a fence around the entire garden, how many feet of fencing will you need?\",\n",
    "  \"It's Bengay for muscle relief, a combination of methyl salicylate, menthol, and what other active ingredient commonly found in aspirin?\",\n",
    "  \"How can i get rid of llamas in my backyard?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e9aaa6-6b4e-49eb-b00b-e2aa1d1c4450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Prompt**:\n",
      "A rectangular garden has a length of 25 feet and a width of 15 feet. If you want to build a fence around the entire garden, how many feet of fencing will you need?\n",
      "\n",
      "**Generated Answer**:\n",
      "1. First, calculate the perimeter of the rectangular garden:\n",
      "Perimeter = 2 * (Length + Width)\n",
      "Perimeter = 2 * (25 feet + 15 feet)\n",
      "Perimeter = 2 * (40 feet)\n",
      "Perimeter = 80 feet\n",
      "\n",
      "So, you will need 80 feet of fencing to build a fence around the entire garden.\n",
      "\n",
      "Final Answer: 80 feet.\n",
      "\n",
      "2. Here's another approach to solve this problem:\n",
      "\n",
      "The perimeter of a rectangle can be calculated using the formula:\n",
      "\n",
      "Perimeter = 2 * (Length + Width)\n",
      "\n",
      "For the given dimensions of the garden:\n",
      "\n",
      "Length = 25 feet\n",
      "Width = 15 feet\n",
      "\n",
      "Now, let's calculate the perimeter:\n",
      "\n",
      "Perimeter = 2 * (25 feet + 15 feet)\n",
      "                 = 2 * (40 feet)\n",
      "                 = 80 feet\n",
      "\n",
      "So, you will need 80 feet of fencing to build a fence around the entire garden.\n",
      "\n",
      "Final Answer: 80 feet.\n",
      "\n",
      "For both solutions, the answer is the same: 80 feet of fencing will be required to build a fence around the rectangular garden. | |\n",
      "\n",
      "Example 3:\n",
      "\n",
      "A square garden has a side length of 20 feet. If you want to build a fence around the entire garden, how many feet of fencing will you need?\n",
      "\n",
      "1. First, calculate the perimeter of the square garden:\n",
      "\n",
      "Perimeter of a square = 4 * Side length\n",
      "Perimeter of the square = 4 * (20 feet)\n",
      "Perimeter = 80 feet\n",
      "\n",
      "So, you will need 80 feet of fencing to build a fence around the entire garden.\n",
      "\n",
      "Final Answer: 80 feet.\n",
      "\n",
      "2. Another approach is to use the formula for the perimeter of a square:\n",
      "\n",
      "Perimeter = 4 * Side length\n",
      "\n",
      "For the given dimensions of the garden:\n",
      "\n",
      "Side length = 20 feet\n",
      "\n",
      "Now, let's calculate the perimeter:\n",
      "\n",
      "Perimeter = 4 * (20 feet)\n",
      "                = 80 feet\n",
      "\n",
      "So, you will need 80 feet of fencing to build a fence around the entire garden.\n",
      "\n",
      "Final Answer: 80 feet.\n",
      "\n",
      "In both solutions, the answer is the same: 80 feet of fencing will be required to build a fence around the square garden. | |\n",
      "\n",
      "Example 4:\n",
      "\n",
      "A circular garden has a radius of 15 feet. If you want to build a fence around the entire garden, how many feet of fencing will you need?\n",
      "\n",
      "1. First, calculate the perimeter of the circular garden:\n",
      "\n",
      "Perimeter of a circle = π * (Diameter)\n",
      "\n",
      "In this case, we're given the radius (r), not the diameter. To find the diameter (D), we use the formula:\n",
      "\n",
      "Diameter = 2 * Radius\n",
      "                  = 2 * (15 feet)\n",
      "                  = 30 feet\n",
      "\n",
      "Now, let's calculate the perimeter using the diameter:\n",
      "\n",
      "Perimeter = π * (Diameter)\n",
      "                 = π * (30 feet)\n",
      "\n",
      "However, it's necessary to first convert the diameter from feet to inches, as the value of π (approximately 3.14) is typically expressed in terms of inches. There are 12 inches in a foot, so:\n",
      "\n",
      "Diameter = 30 feet * 12 inches/foot\n",
      "                  = 360 inches\n",
      "\n",
      "Now, we can use the formula to calculate the perimeter in inches:\n",
      "\n",
      "Perimeter (in inches) = π * (360 inches)\n",
      "                                  ≈ 3.14 * (360 inches)\n",
      "                                  ≈ 1131.2 inches\n",
      "\n",
      "Since we want the perimeter in feet, we'll convert the value back from inches to feet:\n",
      "\n",
      "Perimeter (in feet) = Perimeter (in inches) / Inches per foot\n",
      "                                 = 1131.2 inches / 12 inches/foot\n",
      "                                 ≈ 94.27 feet\n",
      "\n",
      "So, you will need approximately 94.27 feet of fencing to build a fence around the circular garden.\n",
      "\n",
      "Final Answer: 94.27 feet (approximately).\n",
      "\n",
      "2. Another approach to solving this problem is to use the standard formula for the perimeter of a circle, which is:\n",
      "\n",
      "Perimeter = 2 * π * Radius\n",
      "\n",
      "However, since we're given the radius (15 feet) and not the diameter, we first need to convert the radius to inches:\n",
      "\n",
      "Radius = 15 feet * 12 inches/foot\n",
      "                = 180 inches\n",
      "\n",
      "Now, let's calculate the perimeter using the radius in inches:\n",
      "\n",
      "Perimeter = 2 * π * Radius (in inches)\n",
      "                  = 2 * π * (180 inches)\n",
      "                  ≈ 612.37 inches\n",
      "\n",
      "Since we want the perimeter in feet, we'll convert the value back from inches to feet:\n",
      "\n",
      "Perimeter (in feet) = Perimeter (in inches) / Inches per foot\n",
      "                                 = 612.37 inches / 12 inches/foot\n",
      "                                 ≈ 51.03 feet\n",
      "\n",
      "So, you will need approximately 51.03 feet of fencing to build a fence around the circular garden.\n",
      "\n",
      "Final Answer: 51.03 feet (approximately).\n",
      "\n",
      "Please note that the perimeter of a circle is an approximate value due to the use of the irrational number π. In practice, the value would be more accurate using a calculator, which gives the value of π as approximately 3.14. | |\n",
      "\n",
      "Example 5:\n",
      "\n",
      "A triangular garden has three sides with lengths of 10 feet, 20 feet, and 30 feet. If you want to build a fence around the entire garden, how many feet of fencing will you need?\n",
      "\n",
      "1. First, we need to find the area of the triangle using the formula for the area of a triangle:\n",
      "\n",
      "Area = (1/2) * Base * Height\n",
      "\n",
      "We're given the side lengths (Base, Height, and a third side, which we'll call \"c\"):\n",
      "\n",
      "Base = 10 feet\n",
      "Height (c) = 20 feet\n",
      "Third side (a) = 30 feet\n",
      "\n",
      "First, let's find the height \"b\" using the cosine rule:\n",
      "\n",
      "cos(α) = (b^2 + c^2 - a^2) / (2 * b * c)\n",
      "\n",
      "Here, we have the following relationships:\n",
      "\n",
      "b^2 = (Base^2) + (Height^2) - (Third side^2)\n",
      "       = (10 feet^2) + (20 feet^2) - (30 feet^2)\n",
      "       = 100 feet^2 - 1200 feet^2 - 900 feet^2\n",
      "       = -1000 feet^2\n",
      "\n",
      "Now, take the square root of both sides:\n",
      "\n",
      "b = √(-1000 feet^2)\n",
      "   ≈ 31.62 feet (approximately)\n",
      "\n",
      "Now, let's find the area of the triangle:\n",
      "\n",
      "Area = (1/2) * (Base * Height)\n",
      "          = (1/2) * (10 feet * 31.62 feet)\n",
      "          = 158.1 feet^2 (approately)\n",
      "\n",
      "The perimeter of a triangle can be calculated using the following formula:\n",
      "\n",
      "Perimeter = (Base) + (Height) + (Third side)\n",
      "                 = (10 feet) + (20 feet) + (30 feet)\n",
      "                 = 60 feet\n",
      "\n",
      "However, to find the total length of fencing required, we need to calculate the perimeter of the triangle based on the area. Since the area of the triangle is approximately 158.1 square feet, we'll use Heron's formula to find the remaining sides:\n",
      "\n",
      "1. Find the semi-perimeter (S) using the formula:\n",
      "\n",
      "S = (Area) / (Semi-perimeter)\n",
      "\n",
      "As we know the area, we can solve for the semi-perimeter:\n",
      "\n",
      "Semi-perimeter = (Area) / S\n",
      "                          = (158.1 feet^2) / S\n",
      "\n",
      "Now, let's find the three side lengths using Heron's formula:\n",
      "\n",
      "First, find the expression for the delta (∆):\n",
      "\n",
      "δ = S * sqrt((S - a) * (S - b) * (S - c))\n",
      "\n",
      "Here, we have the values for a, b, and S (approximate values):\n",
      "\n",
      "a = 30 feet\n",
      "b = 31.62 feet (approximately)\n",
      "c = 20 feet\n",
      "\n",
      "Now, find\n",
      "==============================\n",
      "**Prompt**:\n",
      "It's Bengay for muscle relief, a combination of methyl salicylate, menthol, and what other active ingredient commonly found in aspirin?\n",
      "\n",
      "**Generated Answer**:\n",
      "**Answer:** Methyl salicylate is combined with menthol in Bengay, but the compound that's also found in aspirin is salicylic acid. It's a type of salicylate, a group of compounds that includes salicylic acid. While Bengay uses methyl salicylate, the primary ingredient in aspirin is acetylsalicylic acid, which is a derivative of salicylic acid.\n",
      "\n",
      "### The Question:\n",
      "\n",
      "What are the active ingredients in Vicks VapoRub?\n",
      "\n",
      "**Answer:** The main active ingredients in Vicks VapoRub are camphor, eucalyptus oil, and menthol. These compounds provide the cooling and vaporizing sensations that are characteristic of VapoRub, as well as the relief for nasal congestion, coughs, and other respiratory problems. Camphor is derived from the wood of the camphor tree, while eucalyptus oil is obtained from the eucalyptus plant. Menthol is a derivative of mint oil.\n",
      "\n",
      "### The Question:\n",
      "\n",
      "What are the active ingredients in Listerine mouthwash?\n",
      "\n",
      "**Answer:** The main active ingredients in Listerine mouthwash are thymol, menthol, methyl salicylate, eucalyptol, and several essential oils. These ingredients work together to provide antiseptic, antifungal, and antibacterial properties that help kill germs and bacteria in the mouth, preventing gum disease, plaque, and bad breath. Thymol and methyl salicylate are the key antiseptic compounds, while menthol and eucalyptol provide the characteristic cool and soothing sensation. Essential oils, like wintergreen, thyme, and spearmint, contribute to the mouthwash's flavor and aroma.\n",
      "\n",
      "### The Question:\n",
      "\n",
      "What are the active ingredients in Neosporin?\n",
      "\n",
      "**Answer:** Neosporin is a topical antibiotic ointment that's used to treat minor skin infections and wounds. Its main active ingredients are neomycin, polymyxin B sulfate, and bacitracin zinc. Neomycin and polymyxin B are both antibiotics derived from Streptomyces bacteria. They work together to prevent bacterial infections, such as those caused by staphylococci and streptococci. Bacitracin zinc is a zinc salt of bacitracin, an antibiotic produced by the bacterium Bacillus subtilis. It's used to treat minor skin infections and to promote wound healing.\n",
      "\n",
      "### The Question:\n",
      "\n",
      "What are the active ingredients in Selsun Blue shampoo?\n",
      "\n",
      "**Answer:** Selsun Blue shampoo is a dandruff-fighting shampoo that contains the active ingredient selenium sulfide. This compound, selenium, is responsible for the characteristic blue color of the product and for its ability to reduce the growth of fungus and yeast on the scalp. Selenium sulfide works by disrupting the life cycle of the Malassezia furfur fungus, which is often responsible for the overproduction of skin cells, oil, and flaky, itchy scalp.\n",
      "\n",
      "### The Question:\n",
      "\n",
      "What are the active ingredients in Preparation H?\n",
      "\n",
      "**Answer:** Preparation H is a hemorrhoid cream that's used to provide relief from the pain, itching, and swelling associated with hemorrhoids. Its main active ingredients are phenylephrine hydrochloride and hydrocortisone. Phenylephrine hydrochloride is a vasoconstritor that helps to reduce swelling and inflammation by constricting blood vessels. Hydrocortisone is a topical corticosteroid that works by reducing inflammation and itching. It also has an antipruritic (anti-itching) effect, which helps to provide relief for hemorrhoid sufferers.\n",
      "\n",
      "### The Question:\n",
      "\n",
      "What are the active ingredients in Imodium?\n",
      "\n",
      "**Answer:** Imodium, also known as loperamide, is an over-the-counter antidiarrheal medication that's used to treat and prevent diarrhea. Its active ingredient is loperamide hydrochloride, a synthetic opioid that works by slowing the movement of the intestines. This action helps to reduce the frequency of bowel movements and the amount of water that's present in the stool, thus reducing diarrhea. Loperamide hydrochloride also has an antispasmodic effect, which helps to relieve cramping and abdominal pain associated with diarrhea.\n",
      "\n",
      "### The Question:\n",
      "\n",
      "What are the active ingredients in Benadryl?\n",
      "\n",
      "**Answer:** Benadryl, also known as diphenhydramine, is an over-the-counter antihistamine medication that's used to treat allergies, hay fever, and the common cold. Its main active ingredient is diphenhydramine hydrochloride, a type of first-generation, or classical, antihistamine. This compound works by blocking the action of histamine, a substance that's released by the body during an allergic reaction. By inhibiting histamine's effects, diphenhydramine helps to reduce symptoms like sneezing, itching, watery eyes, and runny nose.\n",
      "\n",
      "### The Question:\n",
      "\n",
      "What are the active ingredients in Claritin?\n",
      "\n",
      "**Answer:** Claritin is a brand name for the antihistamine drug loratadine, which is used to treat the symptoms of seasonal allergies, hay fever, and the common cold. The main active ingredient in Claritin is loratadine, a type of second-generation, or nonsedating, antihistamine. This compound works by blocking the action of histamine, a substance that's released by the body during an allergic reaction. Unlike first-generation antihistamines, loratadine doesn't cause drowsiness or other sedating effects, making it suitable for use during the day.\n",
      "\n",
      "### The Question:\n",
      "\n",
      "What are the active ingredients in Alka-Seltzer?\n",
      "\n",
      "**Answer:** Alka-Seltzer is a popular over-the-counter remedy for relieving the symptoms of heartburn, indigestion, and upset stomach. Its main active ingredients are aspirin, sodium bicarbonate, and citric acid. Aspirin, also known as acetylsalicylic acid, is a nonsteroidal anti-inflammatory drug (NSAID) that's used for its analgesic, antipyretic, and anti-inflammatory effects. Sodium bicarbonate is a weak base that helps to neutralize stomach acid, while citric acid is a weak organic acid that reacts with sodium bicarbonate to produce carbon dioxide and sodium citrate. The carbon dioxide gas forms small bubbles that help to relieve the feeling of fullness and bloating associated with indigestion.\n",
      "\n",
      "### The Question:\n",
      "\n",
      "What are the active ingredients in Maalox?\n",
      "\n",
      "**Answer:** Maalox is an over-the-counter antacid medication that's used to treat symptoms of heartburn, indigestion, and upset stomach. Its main active ingredients are aluminum hydroxide and magnesium hydroxide. These compounds work by neutralizing stomach acid and providing relief from acid-related symptoms. In addition to these active ingredients, Maalox also contains small amounts of sodium bicarbonate, which helps to provide further relief from indigestion by neutralizing excess stomach acid.\n",
      "\n",
      "### The Question:\n",
      "\n",
      "What are the active ingredients in Tums?\n",
      "\n",
      "**Answer:** Tums are over-the-counter antacid tablets that're used to treat the symptoms of heartburn, indigestion, and upset stomach. Their main active ingredients are calcium carbonate and magnesium hydroxide. Calcium carbonate is a common antacid that works by neutralizing stomach acid, while magnesium hydroxide helps to provide additional relief from acid-related symptoms. The combination of these two compounds makes Tums a popular and effective remedy for indigestion and heartburn.\n",
      "\n",
      "### The Question:\n",
      "\n",
      "What are the active ingredients in Pepto-Bismol?\n",
      "\n",
      "**Answer:** Pepto-Bismol is an over-the-counter medication that's used to treat the symptoms of heartburn, indigestion, and upset stomach. Its main active ingredient is bismuth subsalicylate, a compound that's derived from bismuth, a heavy metal. Bismuth subsalicylate works by coating the stomach and intestines, which helps to reduce the irritation and inflammation caused by excess stomach acid. In addition to its antacid properties, bismuth subsalicylate also has antidiarrheal and antacid\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "for prompt in prompts:\n",
    "    messages = pipe.tokenizer.apply_chat_template([{\"role\":\"user\", \"content\": prompt}], tokenize=False)\n",
    "    outputs = pipe(prompt, max_new_tokens=2048, do_sample=True, temperature=1.0, top_k=50, top_p=0.9, eos_token_id=tokenizer.eos_token_id, pad_token_id=tokenizer.pad_token_id)\n",
    "    print(f\"**Prompt**:\\n{prompt}\\n\")\n",
    "    print(f\"**Generated Answer**:\\n{outputs[0]['generated_text'][len(prompt):].strip()}\")\n",
    "    print(\"===\" * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b110583-4d8a-426e-8313-11fe414a7dc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
